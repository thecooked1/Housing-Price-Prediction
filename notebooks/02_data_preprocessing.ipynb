{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeeb1934a644e693",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Feature Engineering\n",
    "\n",
    "**Objective:** Transform raw housing data into a clean, reproducible format for machine learning. This notebook implements the core preprocessing pipeline including missing value imputation, outlier handling, and categorical encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef8cdb5e671283",
   "metadata": {},
   "source": [
    "#### 1. Modular Imports and Data Loading\n",
    "\n",
    "We start by importing our custom logic from the `src` directory. By keeping our cleaning functions in a separate _Python_ module, we ensure that our data pipeline is reproducible and follows professional modular design."
   ]
  },
  {
   "cell_type": "code",
   "id": "62c830511b79f1ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "from src.data_processing import preprocess_data, handle_outliers\n",
    "\n",
    "df = pd.read_csv('../data/raw/housing.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "638b973bb7a7ed9f",
   "metadata": {},
   "source": [
    "#### 2. The Transformation Pipeline\n",
    "\n",
    "We apply the `preprocess_data` function to standardize the dataset.\n",
    "* **Target Standardizing:** Renamed median_house_value to Price.\n",
    "* **Missing Values:** Numerical columns are imputed.\n",
    "* **Feature Engineering:** We created Rooms_Per_Household and Bedrooms_Per_Room.\n",
    "\n",
    "**Justification for Decision:**\n",
    "We used the Median strategy for filling missing values in `total_bedrooms`. In `housing data`, `total bedroom` counts are often skewed by extremely large apartment complexes or blocks. The median is more robust to these outliers than the mean, providing a more accurate \"typical\" value for the district."
   ]
  },
  {
   "cell_type": "code",
   "id": "106269680a54eb3",
   "metadata": {},
   "source": [
    "# Transformation Pipeline\n",
    "df_clean = preprocess_data(df, fill_strategy='median')\n",
    "# Justification: Median was used for total_bedrooms because the\n",
    "# distribution is skewed; mean would be affected by extreme values."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6cae335215105beb",
   "metadata": {},
   "source": [
    "#### 3. Outlier Detection and Capping\n",
    "\n",
    "Using the **Interquartile Range (IQR)** method, we address outliers in key numerical features. We target features that show high variance: `Price`, `median_income`, `total_rooms`, `total_bedrooms`, `population`, and `households`.\n",
    "\n",
    "Removing values outside\n",
    "\n",
    "**1.5 × IQR1.5 × IQR**\n",
    "\n",
    "ensures that our linear models are not skewed by extreme geographical anomalies or data entry errors."
   ]
  },
  {
   "cell_type": "code",
   "id": "7e90e9f9fa6b9c6f",
   "metadata": {},
   "source": [
    "df_no_outliers = handle_outliers(df_clean, ['Price', 'median_income', 'total_rooms', 'total_bedrooms', 'population', 'households'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "85237363e96d91e6",
   "metadata": {},
   "source": [
    "#### 4. Categorical Encoding and Data Export\n",
    "\n",
    "Finally, we convert the categorical `ocean_proximity` feature into numerical format using **One-Hot Encoding.** We use `drop_first=True` to avoid the \"dummy variable trap\" (multicollinearity), which is essential for stable **Linear Regression performance.**\n",
    "\n",
    "The processed, immutable data is then saved to the processed data folder."
   ]
  },
  {
   "cell_type": "code",
   "id": "a50435f8b17ac13c",
   "metadata": {},
   "source": [
    "# Type Conversion: One-Hot Encoding\n",
    "df_final = pd.get_dummies(df_no_outliers, columns=['ocean_proximity'], drop_first=True)\n",
    "\n",
    "df_final.to_csv('../data/processed/cleaned_housing.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "586f33e16d7fb51a",
   "metadata": {},
   "source": [
    "#### 5. Final Preprocessing Verification\n",
    "\n",
    "We check the state of the final dataframe to ensure all transformations were applied correctly and that no null values remain."
   ]
  },
  {
   "cell_type": "code",
   "id": "cc47a5f3097a7214",
   "metadata": {},
   "source": [
    "# Display first five rows and last 5 rows\n",
    "print(\"----------- PROCESSED HEAD -----------\\n\")\n",
    "print(df_final.head(),\"\\n\")\n",
    "print(\"----------- PROCESSED TAIL -----------\\n\")\n",
    "print(df_final.tail(),\"\\n\")\n",
    "\n",
    "# Check the new columns specifically\n",
    "print(\"----------- NEW COLUMNS CREATED -----------\\n\")\n",
    "print(df_final[['Price', 'Rooms_Per_Household', 'Bedrooms_Per_Room']].head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"----------- MISSING VALUES -----------\\n\")\n",
    "print(df_final.isnull().sum(), \"\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
